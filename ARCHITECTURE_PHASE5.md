# ðŸ—ï¸ PHASE 5 - SYSTEM ARCHITECTURE

## AI Assistant / Coach Bot - Technical Architecture

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE                            â”‚
â”‚                    React + Tailwind CSS                          â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  AssistantPage (Full Page)                             â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚ Sidebar      â”‚ AssistantChat                    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ â€¢ Match      â”‚ â€¢ AssistantMessage (messages)    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚   Selector   â”‚ â€¢ Input + Send                   â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ â€¢ AI Status  â”‚ â€¢ Loading states                 â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ â€¢ Help Info  â”‚ â€¢ Error handling                 â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  useAssistant Hook                                     â”‚    â”‚
â”‚  â”‚  â€¢ messages state                                      â”‚    â”‚
â”‚  â”‚  â€¢ sendQuery()                                         â”‚    â”‚
â”‚  â”‚  â€¢ React Query integration                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/REST
                       â”‚ POST /api/v1/assistant/query
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       API GATEWAY                                â”‚
â”‚                    FastAPI + Uvicorn                             â”‚
â”‚                                                                  â”‚
â”‚  ðŸ“ /api/v1/assistant/query                                     â”‚
â”‚     â€¢ Accepts: AssistantQueryRequest                            â”‚
â”‚     â€¢ Returns: AssistantResponse                                â”‚
â”‚     â€¢ Handler: query_assistant()                                â”‚
â”‚                                                                  â”‚
â”‚  ðŸ“ /api/v1/assistant/test                                      â”‚
â”‚     â€¢ Tests LLM connection                                      â”‚
â”‚     â€¢ Returns: LLMTestResponse                                  â”‚
â”‚                                                                  â”‚
â”‚  ðŸ“ /api/v1/assistant/health                                    â”‚
â”‚     â€¢ Health check                                              â”‚
â”‚     â€¢ Returns: status + config                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ASSISTANT SERVICE LAYER                        â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AssistantService.handle_query()                           â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  Step 1: Parse Intent                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ IntentParser.parse(user_query)                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Regex pattern matching                           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Entity extraction (jersey #, team, event type)   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Returns: intent + entities + confidence          â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  Step 2: Build SQL Queries                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ QueryBuilder (SQLAlchemy)                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ Physical Metrics:                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_top_distance_players()                       â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_top_speed_players()                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_workload_analysis()                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_player_metrics()                             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ xT Metrics:                                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_top_xt_players()                             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_player_xt_metrics()                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ Tactical:                                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_latest_tactical_snapshot()                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_pressing_timeline()                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_transitions()                                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ Events:                                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_events()                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_top_events_by_xt()                           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ Meta:                                              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ get_match_info()                                 â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ compare_teams()                                  â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  Step 3: Execute Queries                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ PostgreSQL Database                                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ PlayerMetrics                                    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ XTMetrics                                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ TacticalSnapshot                                 â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Event                                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ PlayerTrack                                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Match                                            â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  Step 4: Build Context                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Context Builder (prompts.py)                       â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ build_context():                                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ format_match_info()                              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ format_player_metrics()                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ format_xt_metrics()                              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ format_tactical_summary()                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ format_events_summary()                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ Output: Structured context string                  â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  Step 5: Call LLM                                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ LLMClient.generate_answer()                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ system_prompt: SYSTEM_PROMPT                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ user_prompt: context                             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Returns: natural language answer                 â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  Step 6: Generate Actions                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ _generate_actions()                                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Maps intent to UI actions                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Creates navigation suggestions                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Links to dashboards/replay                       â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  Step 7: Assemble Response                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ AssistantResponse                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ answer: str                                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ data_used: dict                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ suggested_actions: list                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ follow_up_questions: list                        â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       LLM PROVIDER LAYER                         â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LLMClient (Abstract Base)                                 â”‚ â”‚
â”‚  â”‚ â€¢ async generate_answer(system, user) -> str              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ OpenAIClient â”‚AnthropicClientâ”‚LocalLLMClientâ”‚MockLLMClientâ”‚ â”‚
â”‚  â”‚              â”‚              â”‚              â”‚             â”‚ â”‚
â”‚  â”‚ GPT-4o       â”‚ Claude 3.5   â”‚ Ollama       â”‚ Testing     â”‚ â”‚
â”‚  â”‚ GPT-3.5      â”‚ Claude 3     â”‚ Llama2/3     â”‚ No API Key  â”‚ â”‚
â”‚  â”‚              â”‚              â”‚ Mistral      â”‚             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚  Factory: create_llm_client(provider, api_key, model)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EXTERNAL LLM SERVICES                        â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ OpenAI API      â”‚  â”‚ Anthropic API    â”‚  â”‚ Local Ollama â”‚  â”‚
â”‚  â”‚ api.openai.com  â”‚  â”‚ api.anthropic.comâ”‚  â”‚ localhost    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Diagram

### Backend Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Backend Structure                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  app/assistant/                                            â”‚
â”‚  â”œâ”€â”€ __init__.py                                           â”‚
â”‚  â”œâ”€â”€ service.py                 (350 lines)                â”‚
â”‚  â”‚   â”œâ”€â”€ IntentParser class                               â”‚
â”‚  â”‚   â”‚   â””â”€â”€ parse(query) -> intent + entities            â”‚
â”‚  â”‚   â””â”€â”€ AssistantService class                           â”‚
â”‚  â”‚       â”œâ”€â”€ handle_query()                               â”‚
â”‚  â”‚       â”œâ”€â”€ _retrieve_data()                             â”‚
â”‚  â”‚       â””â”€â”€ _generate_actions()                          â”‚
â”‚  â”‚                                                         â”‚
â”‚  â”œâ”€â”€ sql_builder.py             (600 lines)                â”‚
â”‚  â”‚   â””â”€â”€ QueryBuilder class                               â”‚
â”‚  â”‚       â”œâ”€â”€ Physical: get_top_distance_players()         â”‚
â”‚  â”‚       â”œâ”€â”€ Physical: get_top_speed_players()            â”‚
â”‚  â”‚       â”œâ”€â”€ Physical: get_workload_analysis()            â”‚
â”‚  â”‚       â”œâ”€â”€ Physical: get_player_metrics()               â”‚
â”‚  â”‚       â”œâ”€â”€ xT: get_top_xt_players()                     â”‚
â”‚  â”‚       â”œâ”€â”€ xT: get_player_xt_metrics()                  â”‚
â”‚  â”‚       â”œâ”€â”€ Tactical: get_latest_tactical_snapshot()     â”‚
â”‚  â”‚       â”œâ”€â”€ Tactical: get_pressing_timeline()            â”‚
â”‚  â”‚       â”œâ”€â”€ Tactical: get_transitions()                  â”‚
â”‚  â”‚       â”œâ”€â”€ Events: get_events()                         â”‚
â”‚  â”‚       â”œâ”€â”€ Events: get_top_events_by_xt()               â”‚
â”‚  â”‚       â”œâ”€â”€ Meta: get_match_info()                       â”‚
â”‚  â”‚       â””â”€â”€ Meta: compare_teams()                        â”‚
â”‚  â”‚                                                         â”‚
â”‚  â”œâ”€â”€ llm_client.py              (200 lines)                â”‚
â”‚  â”‚   â”œâ”€â”€ LLMClient (ABC)                                  â”‚
â”‚  â”‚   â”œâ”€â”€ OpenAIClient                                     â”‚
â”‚  â”‚   â”œâ”€â”€ AnthropicClient                                  â”‚
â”‚  â”‚   â”œâ”€â”€ LocalLLMClient                                   â”‚
â”‚  â”‚   â”œâ”€â”€ MockLLMClient                                    â”‚
â”‚  â”‚   â”œâ”€â”€ create_llm_client()                              â”‚
â”‚  â”‚   â””â”€â”€ test_llm_connection()                            â”‚
â”‚  â”‚                                                         â”‚
â”‚  â””â”€â”€ prompts.py                 (250 lines)                â”‚
â”‚      â”œâ”€â”€ SYSTEM_PROMPT                                     â”‚
â”‚      â”œâ”€â”€ CONTEXT_TEMPLATE                                  â”‚
â”‚      â”œâ”€â”€ format_match_info()                              â”‚
â”‚      â”œâ”€â”€ format_player_metrics()                          â”‚
â”‚      â”œâ”€â”€ format_xt_metrics()                              â”‚
â”‚      â”œâ”€â”€ format_tactical_summary()                        â”‚
â”‚      â”œâ”€â”€ format_events_summary()                          â”‚
â”‚      â”œâ”€â”€ build_context()                                  â”‚
â”‚      â””â”€â”€ FOLLOW_UP_SUGGESTIONS                            â”‚
â”‚                                                            â”‚
â”‚  app/api/routers/                                          â”‚
â”‚  â””â”€â”€ assistant.py               (100 lines)                â”‚
â”‚      â”œâ”€â”€ query_assistant()                                â”‚
â”‚      â”œâ”€â”€ test_llm()                                       â”‚
â”‚      â””â”€â”€ health_check()                                   â”‚
â”‚                                                            â”‚
â”‚  app/schemas/                                              â”‚
â”‚  â””â”€â”€ assistant_schemas.py       (80 lines)                 â”‚
â”‚      â”œâ”€â”€ AssistantQueryRequest                            â”‚
â”‚      â”œâ”€â”€ AssistantSuggestedAction                         â”‚
â”‚      â”œâ”€â”€ AssistantResponse                                â”‚
â”‚      â””â”€â”€ LLMTestResponse                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Frontend Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend Structure                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  src/hooks/                                                â”‚
â”‚  â””â”€â”€ useAssistant.js            (100 lines)                â”‚
â”‚      â”œâ”€â”€ useAssistant()                                    â”‚
â”‚      â”‚   â”œâ”€â”€ messages state                               â”‚
â”‚      â”‚   â”œâ”€â”€ sendQuery()                                  â”‚
â”‚      â”‚   â”œâ”€â”€ clearMessages()                              â”‚
â”‚      â”‚   â””â”€â”€ isLoading, error                             â”‚
â”‚      â”œâ”€â”€ useLLMTest()                                     â”‚
â”‚      â””â”€â”€ useAssistantHealth()                             â”‚
â”‚                                                            â”‚
â”‚  src/components/assistant/                                 â”‚
â”‚  â”œâ”€â”€ AssistantMessage.jsx       (120 lines)                â”‚
â”‚  â”‚   â”œâ”€â”€ Message bubble rendering                         â”‚
â”‚  â”‚   â”œâ”€â”€ User vs assistant styling                        â”‚
â”‚  â”‚   â”œâ”€â”€ Data summary display                             â”‚
â”‚  â”‚   â”œâ”€â”€ Action buttons                                   â”‚
â”‚  â”‚   â”œâ”€â”€ Follow-up questions                              â”‚
â”‚  â”‚   â””â”€â”€ Timestamp                                        â”‚
â”‚  â”‚                                                         â”‚
â”‚  â”œâ”€â”€ AssistantChat.jsx          (250 lines)                â”‚
â”‚  â”‚   â”œâ”€â”€ Chat interface                                   â”‚
â”‚  â”‚   â”œâ”€â”€ Message list                                     â”‚
â”‚  â”‚   â”œâ”€â”€ Input + send button                              â”‚
â”‚  â”‚   â”œâ”€â”€ Loading indicator                                â”‚
â”‚  â”‚   â”œâ”€â”€ Welcome screen                                   â”‚
â”‚  â”‚   â”œâ”€â”€ Quick questions                                  â”‚
â”‚  â”‚   â”œâ”€â”€ Action handler (navigation)                      â”‚
â”‚  â”‚   â””â”€â”€ Auto-scroll                                      â”‚
â”‚  â”‚                                                         â”‚
â”‚  â””â”€â”€ AssistantButton.jsx        (50 lines)                 â”‚
â”‚      â”œâ”€â”€ Compact mode                                     â”‚
â”‚      â”œâ”€â”€ Full button mode                                 â”‚
â”‚      â””â”€â”€ Navigation with context                          â”‚
â”‚                                                            â”‚
â”‚  src/pages/                                                â”‚
â”‚  â””â”€â”€ AssistantPage.jsx          (300 lines)                â”‚
â”‚      â”œâ”€â”€ Full-page layout                                 â”‚
â”‚      â”œâ”€â”€ Sidebar:                                         â”‚
â”‚      â”‚   â”œâ”€â”€ Match selector                               â”‚
â”‚      â”‚   â”œâ”€â”€ AI status display                            â”‚
â”‚      â”‚   â””â”€â”€ Help section                                 â”‚
â”‚      â””â”€â”€ Main area: AssistantChat                         â”‚
â”‚                                                            â”‚
â”‚  src/services/                                             â”‚
â”‚  â””â”€â”€ api.js                     (updated)                  â”‚
â”‚      â””â”€â”€ assistantApi                                     â”‚
â”‚          â”œâ”€â”€ query()                                      â”‚
â”‚          â”œâ”€â”€ testLLM()                                    â”‚
â”‚          â””â”€â”€ health()                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow Diagram

### Query Processing Flow

```
1. USER INPUT
   â†“
   "Who covered the most distance?"
   â†“
   
2. FRONTEND (useAssistant)
   â†“
   sendQuery(query, { matchId })
   â†“
   POST /api/v1/assistant/query
   {
     "query": "Who covered the most distance?",
     "match_id": "abc-123"
   }
   â†“

3. FASTAPI ROUTER
   â†“
   query_assistant(request, db)
   â†“
   AssistantService(db)
   â†“

4. INTENT PARSING
   â†“
   IntentParser.parse(query)
   â†“
   {
     "intent": "player_distance",
     "entities": {},
     "confidence": 0.8
   }
   â†“

5. SQL QUERY BUILDING
   â†“
   QueryBuilder.get_top_distance_players(match_id, limit=10)
   â†“
   SQLAlchemy Query:
   SELECT PlayerMetrics.*, PlayerTrack.jersey_number
   FROM player_metrics
   JOIN player_tracks ...
   WHERE match_id = 'abc-123'
   ORDER BY total_distance_m DESC
   LIMIT 10
   â†“

6. DATABASE QUERY
   â†“
   PostgreSQL Execution
   â†“
   Results: [
     {player_id, jersey, distance_km, ...},
     ...
   ]
   â†“

7. CONTEXT BUILDING
   â†“
   build_context(
     user_query,
     match_info,
     player_metrics=[...]
   )
   â†“
   """
   # Match Context
   ## Match Information
   - Match ID: abc-123
   ...
   
   ## Retrieved Data
   ### Physical Metrics
   - Player #10: 12.5 km, ...
   - Player #7: 11.8 km, ...
   """
   â†“

8. LLM GENERATION
   â†“
   LLMClient.generate_answer(SYSTEM_PROMPT, context)
   â†“
   [API Call to OpenAI/Anthropic/Local]
   â†“
   "Player #10 covered the most distance in the match with 12.5 km. 
    This included 15 high-intensity sprints and a maximum speed of 
    32.1 km/h. Their stamina remained at 78% by the end of the match..."
   â†“

9. ACTION GENERATION
   â†“
   _generate_actions(intent, data, match_id)
   â†“
   [
     {
       "type": "open_page",
       "page": "player_metrics",
       "match_id": "abc-123",
       "label": "View Player Metrics Dashboard"
     },
     {
       "type": "open_page",
       "page": "heatmap",
       "player_id": "...",
       "label": "View Heatmap for Player #10"
     }
   ]
   â†“

10. RESPONSE ASSEMBLY
    â†“
    AssistantResponse {
      answer: "Player #10...",
      data_used: {top_player: {...}},
      suggested_actions: [...],
      follow_up_questions: [...]
    }
    â†“

11. FRONTEND DISPLAY
    â†“
    useAssistant receives response
    â†“
    Updates messages state
    â†“
    AssistantMessage renders:
    â€¢ Answer text
    â€¢ Data summary
    â€¢ Action buttons
    â€¢ Follow-up suggestions
```

---

## Database Schema Usage

### Tables Queried by Assistant

```sql
-- Physical Metrics (Phase 2)
player_metrics
  â”œâ”€ total_distance_m
  â”œâ”€ max_speed_ms
  â”œâ”€ avg_speed_ms
  â”œâ”€ sprint_count
  â”œâ”€ stamina_index
  â””â”€ high_intensity_distance_m

-- xT Metrics (Phase 3)
xt_metrics
  â”œâ”€ total_xt_gain
  â”œâ”€ danger_score
  â”œâ”€ pass_xt, carry_xt, shot_xt
  â””â”€ pass_count, carry_count, shot_count

-- Tactical (Phase 3)
tactical_snapshots
  â”œâ”€ formation
  â”œâ”€ formation_confidence
  â”œâ”€ pressing_intensity
  â”œâ”€ team_compactness
  â”œâ”€ defensive_line_height
  â””â”€ block_type

transition_metrics
  â”œâ”€ transition_type
  â”œâ”€ duration_seconds
  â”œâ”€ distance_covered_m
  â””â”€ avg_speed_ms

-- Events (Phase 3)
events
  â”œâ”€ event_type (pass/carry/shot)
  â”œâ”€ start_x_m, start_y_m
  â”œâ”€ end_x_m, end_y_m
  â”œâ”€ distance_m
  â”œâ”€ velocity_ms
  â””â”€ xt_value

-- Tracks (Phase 1)
player_tracks
  â”œâ”€ jersey_number
  â”œâ”€ team_side
  â””â”€ object_class

-- Matches (Phase 1)
matches
  â”œâ”€ match_name
  â”œâ”€ match_date
  â”œâ”€ home_team_name
  â””â”€ away_team_name
```

---

## Intent Classification

### Intent â†’ Query Mapping

| Intent | Patterns | Query Functions | Tables |
|--------|----------|----------------|--------|
| `player_distance` | "most distance", "ran", "covered" | `get_top_distance_players` | player_metrics, player_tracks |
| `player_speed` | "fastest", "quickest", "max speed" | `get_top_speed_players` | player_metrics, player_tracks |
| `player_stamina` | "stamina", "tired", "fatigue" | `get_workload_analysis` | player_metrics, player_tracks |
| `player_xt` | "xT", "threat", "danger" | `get_top_xt_players` | xt_metrics, player_tracks |
| `tactical` | "formation", "pressing", "defensive" | `get_latest_tactical_snapshot` | tactical_snapshots |
| `events` | "pass", "shot", "carry" | `get_events`, `get_top_events_by_xt` | events, player_tracks |
| `team_comparison` | "compare", "teams", "versus" | `compare_teams` | All metrics tables |
| `general` | "summary", "overview", "tell me" | Multiple queries | All tables |

---

## LLM Provider Architecture

### Provider Selection Flow

```
Environment Variable: LLM_PROVIDER
    â†“
create_llm_client(provider, api_key, model)
    â†“
    â”œâ”€ "openai" â†’ OpenAIClient
    â”‚   â”œâ”€ Base URL: https://api.openai.com/v1/chat/completions
    â”‚   â”œâ”€ Models: gpt-4o, gpt-3.5-turbo, gpt-4-turbo
    â”‚   â””â”€ Auth: Bearer token
    â”‚
    â”œâ”€ "anthropic" â†’ AnthropicClient
    â”‚   â”œâ”€ Base URL: https://api.anthropic.com/v1/messages
    â”‚   â”œâ”€ Models: claude-3-5-sonnet, claude-3-opus
    â”‚   â””â”€ Auth: x-api-key header
    â”‚
    â”œâ”€ "local" â†’ LocalLLMClient
    â”‚   â”œâ”€ Base URL: http://localhost:11434 (Ollama)
    â”‚   â”œâ”€ Models: llama2, llama3, mistral, codellama
    â”‚   â””â”€ Auth: None
    â”‚
    â””â”€ "mock" â†’ MockLLMClient
        â””â”€ Returns: Placeholder response for testing
```

### LLM Client Interface

```python
class LLMClient(ABC):
    """Abstract base for all LLM providers"""
    
    @abstractmethod
    async def generate_answer(
        self, 
        system_prompt: str,
        user_prompt: str
    ) -> str:
        """Generate answer from LLM"""
        pass

# All providers implement this interface
# Switching providers = changing environment variable
```

---

## API Endpoint Specification

### POST /api/v1/assistant/query

**Request:**
```json
{
  "query": "Who covered the most distance?",
  "match_id": "uuid",
  "team_id": "uuid (optional)",
  "player_id": "uuid (optional)"
}
```

**Response:**
```json
{
  "answer": "Player #10 covered the most distance...",
  "data_used": {
    "top_player": {
      "jersey": 10,
      "distance_km": 12.5,
      "sprint_count": 15
    }
  },
  "suggested_actions": [
    {
      "type": "open_page",
      "page": "player_metrics",
      "match_id": "uuid",
      "label": "View Player Metrics Dashboard"
    }
  ],
  "follow_up_questions": [
    "Show me this player's heatmap",
    "Compare this player with teammates"
  ]
}
```

### GET /api/v1/assistant/test

**Response:**
```json
{
  "status": "success",
  "provider": "openai",
  "model": "gpt-4o",
  "response": "Hello, I'm working!"
}
```

### GET /api/v1/assistant/health

**Response:**
```json
{
  "status": "healthy",
  "service": "AI Assistant",
  "llm_provider": "openai",
  "llm_configured": true
}
```

---

## Performance Considerations

### Response Time Breakdown

```
Total Time: 1-3 seconds (typical)

â”œâ”€ Intent Parsing: 5-10ms
â”œâ”€ SQL Query: 50-200ms
â”œâ”€ Context Building: 10-20ms
â”œâ”€ LLM Generation: 500-2000ms (varies by provider)
â””â”€ Response Assembly: 5-10ms

Factors:
â€¢ Database size
â€¢ LLM provider speed
â€¢ Network latency
â€¢ Query complexity
```

### Optimization Strategies

1. **Database Indexing**
   - Index on `match_id` (all tables)
   - Index on `player_id` (all tables)
   - Index on `timestamp_seconds` (events, tactical_snapshots)

2. **Query Limits**
   - Default limit: 10 results
   - Prevents excessive data retrieval

3. **LLM Token Limits**
   - Max context: ~2000 tokens
   - Max response: ~1000 tokens
   - Prevents slow/expensive responses

4. **Caching (Future)**
   - Cache frequent queries
   - Cache LLM responses for identical queries
   - Redis integration

---

## Security Considerations

### API Key Management

```
Environment Variables (Never commit):
  â”œâ”€ LLM_API_KEY â†’ Stored in .env
  â”œâ”€ Access â†’ Backend only
  â””â”€ Frontend â†’ Never exposed

Backend validates all requests
Frontend cannot access API keys directly
```

### Input Validation

```
Request Validation:
  â”œâ”€ Query length: max 500 characters
  â”œâ”€ UUIDs: validated format
  â””â”€ SQL injection: Prevented by SQLAlchemy
```

### Rate Limiting (Recommended)

```
Implement rate limiting:
  â”œâ”€ Per user: 10 queries/minute
  â”œâ”€ Per IP: 20 queries/minute
  â””â”€ Global: 100 queries/minute
```

---

## Monitoring & Logging

### Logged Events

```
Assistant Query:
  â”œâ”€ User query
  â”œâ”€ Intent detected
  â”œâ”€ Match context
  â”œâ”€ LLM provider
  â”œâ”€ Response time
  â””â”€ Success/error

LLM Calls:
  â”œâ”€ Provider
  â”œâ”€ Model
  â”œâ”€ Token usage
  â”œâ”€ Cost (estimated)
  â””â”€ Latency
```

### Metrics to Track

```
â€¢ Total queries
â€¢ Queries per intent type
â€¢ Average response time
â€¢ LLM success rate
â€¢ Error rate
â€¢ Popular queries
â€¢ Cost per query (cloud providers)
```

---

## Error Handling

### Backend Error Scenarios

| Error | Cause | Response |
|-------|-------|----------|
| No match context | `match_id` not provided | "Please select a match first." |
| Match not found | Invalid `match_id` | "Match not found: {id}" |
| No data | Query returns empty | "I don't have enough data..." |
| LLM error | API failure | "I encountered an error: {error}" |
| Timeout | LLM too slow | "Request timed out. Try again." |

### Frontend Error Handling

```
useAssistant hook:
  â”œâ”€ onError â†’ Add error message to chat
  â”œâ”€ Display â†’ Red error bubble
  â””â”€ Retry â†’ User can resend query
```

---

## Extensibility

### Adding New Intent Types

1. Add pattern to `IntentParser.PATTERNS`
2. Add query function to `QueryBuilder`
3. Add case to `AssistantService._retrieve_data()`
4. Add action mapping to `_generate_actions()`
5. Update prompts if needed

### Adding New LLM Providers

1. Create new client class inheriting `LLMClient`
2. Implement `generate_answer()` method
3. Add case to `create_llm_client()` factory
4. Document provider setup

### Adding Custom Queries

```python
# sql_builder.py
def get_custom_metric(self, match_id):
    # Your custom query
    pass

# service.py
if intent == "custom":
    data = self.query_builder.get_custom_metric(match_id)
```

---

## Testing Strategy

### Unit Tests

```
â€¢ IntentParser.parse() â†’ All intent types
â€¢ QueryBuilder methods â†’ Mock database
â€¢ LLMClient â†’ Mock responses
â€¢ Context builders â†’ Format validation
```

### Integration Tests

```
â€¢ Full query flow â†’ End-to-end
â€¢ Database queries â†’ Real data
â€¢ LLM calls â†’ Mock provider
```

### E2E Tests

```
â€¢ Frontend â†’ Backend â†’ LLM â†’ Frontend
â€¢ User journey scenarios
â€¢ Error scenarios
```

---

## Deployment

### Environment Setup

```bash
# Production
LLM_PROVIDER=openai
LLM_API_KEY=sk-prod-key
LLM_MODEL=gpt-4o

# Staging
LLM_PROVIDER=openai
LLM_API_KEY=sk-staging-key
LLM_MODEL=gpt-3.5-turbo

# Development
LLM_PROVIDER=mock
```

### Docker Support

```dockerfile
# Add to backend Dockerfile
ENV LLM_PROVIDER=${LLM_PROVIDER}
ENV LLM_API_KEY=${LLM_API_KEY}
ENV LLM_MODEL=${LLM_MODEL}
```

---

**Phase 5 architecture complete and ready for production!** ðŸš€
